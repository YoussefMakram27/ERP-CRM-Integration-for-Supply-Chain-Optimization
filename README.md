ğŸš€ ERPâ€“CRM Integration for Supply Chain Optimization
ğŸ§  End-to-End Data Engineering Project | PySpark | SQL | Data Warehouse | ETL










ğŸ­ Problem Statement

Industrial companies often manage their operations through two separate systems:

ERP systems â†’ handle procurement, suppliers, and inventory.

CRM systems â†’ handle sales, customers, and returns.

However, these systems operate in silos â€” making it difficult for supply chain managers to:

Detect low-stock risks

Forecast demand trends

Evaluate supplier performance

Gain a unified view of business performance

ğŸ¯ Project Goal

Design and implement an end-to-end data pipeline that integrates ERP and CRM data into a centralized data warehouse, enabling:
âœ… Historical supply chain analytics
âœ… Data-driven decision-making
âœ… Scalable architecture for future tools (Airflow, dbt, Kafka)

ğŸ§© Data Sources

All source data were provided as CSV files (simulating ERP & CRM exports).

System	Table	Description
CRM	crm_customers	Customer master data
	crm_sales_orders	Sales orders by customers
	crm_returns	Returned items & reasons
	crm_sales_leads	Lead pipeline information
ERP	erp_products	Product catalog with pricing & supplier info
	erp_suppliers	Supplier details and reliability
	erp_inventory	Stock levels per warehouse
	erp_inventory_transactions	Inventory movements (in/out)
	erp_purchase_orders	Purchase orders placed with suppliers
ğŸ§± Data Architecture

The pipeline follows a Medallion Architecture (Bronze â†’ Silver â†’ Gold):

        +------------------------+
        |     CRM / ERP CSVs     |
        +------------------------+
                   â†“
          [ BRONZE LAYER ]
          Raw ingestion zone
          - Truncate & Insert from CSVs
          - Minimal transformations
                   â†“
          [ SILVER LAYER ]
          Cleansed & standardized data
          - Type casting, deduplication
          - Standard date formats
          - Trim spaces, remove invalid values
          - Added metadata: source_file, load_datetime
          - Merge (UPSERT) operations
                   â†“
          [ GOLD LAYER ]
          Business-ready warehouse (Star Schema)
          - 5 Dimensions
          - 4 Fact Tables
                   â†“
           Analytics & Insights

ğŸ¥‡ Gold Layer: Star Schema Design
ğŸ§® Fact Tables
Fact Table	Description	Grain
fact_sales	Customer sales transactions	1 row per order
fact_inventory	Daily inventory snapshots	1 row per SKU per warehouse per day
fact_returns	Returned items	1 row per return
fact_purchases	Purchase orders to suppliers	1 row per order
ğŸ§© Dimension Tables
Dimension	Description
dim_date	All calendar dates from 2020â€“2025
dim_customer	Customer attributes (industry, location, manager)
dim_product	Product attributes (category, price, supplier link)
dim_supplier	Supplier performance data
dim_warehouse	Warehouse information
âš™ï¸ Technologies & Tools
Category	Tools / Languages
Processing Framework	PySpark
Query Language	SQL
Storage Format	CSV â†’ Tables (Bronze/Silver/Gold)
Version Control	GitHub
Future Integrations (Planned)	Airflow (orchestration), dbt (transformation mgmt), Kafka (streaming ingestion)
ğŸ§  Key Features

âœ… ETL Pipeline Design (Bronze â†’ Silver â†’ Gold)
âœ… Data Cleansing & Validation
âœ… Schema Enforcement & Type Standardization
âœ… Merge Logic for Incremental Loads
âœ… Dimensional Modeling (Star Schema)
âœ… Analytical Layer for Business Insights
âœ… Scalable Architecture for Future Automation

ğŸ“Š Example Use Cases Enabled

ğŸ§¾ Sales Performance â†’ Total revenue by region, product, or time

ğŸ“¦ Inventory Management â†’ Detect low-stock and replenishment needs

ğŸ” Return Analysis â†’ Identify high-return products

ğŸšš Supplier Evaluation â†’ Compare suppliers by reliability and lead time

ğŸ“ Repository Structure
ERP-CRM-Integration-for-Supply-Chain-Optimization/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ crm_customers.csv
â”‚   â”œâ”€â”€ crm_sales_orders.csv
â”‚   â””â”€â”€ ... (ERP & CRM CSV files)
â”‚
â”œâ”€â”€ bronze/
â”‚   â””â”€â”€ create_bronze_tables.sql
â”‚
â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ transform_clean_data.sql
â”‚   â”œâ”€â”€ merge_silver_tables.sql
â”‚
â”œâ”€â”€ gold/
â”‚   â”œâ”€â”€ dim_date.sql
â”‚   â”œâ”€â”€ dim_customer.sql
â”‚   â”œâ”€â”€ fact_sales.sql
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ etl_pipeline_pyspark.ipynb
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

ğŸ“ˆ Results

After processing, all data is unified in a clean data warehouse (Gold Layer) ready for:

BI dashboards

Supply chain KPIs

Predictive analytics (future extensions)

Example KPIs derived:

ğŸ§¾ Total Sales Revenue

ğŸ“‰ Low Stock Alerts

ğŸ“ˆ Supplier Reliability Trends

ğŸ”„ Return Rates per Product

ğŸ”® Future Enhancements

ğŸš€ Airflow â€“ Automate ETL pipelines
ğŸ§± dbt â€“ Version-controlled SQL transformations
ğŸ“¡ Kafka â€“ Real-time streaming data ingestion
ğŸ“Š Power BI / Looker â€“ Visualization layer

ğŸ‘¨â€ğŸ’» Author

Youssef M. Makram
Data Engineer passionate about building scalable data systems and turning raw data into actionable insights.

ğŸ“« LinkedIn
 â€¢ GitHub

â­ If You Like This Project

Give it a â­ on GitHub â€” it really helps to showcase my work!
